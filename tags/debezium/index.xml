<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Debezium on facelezzzz</title><link>https://facelezzzz.github.io/tags/debezium/</link><description>Recent content in Debezium on facelezzzz</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 18 Sep 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://facelezzzz.github.io/tags/debezium/index.xml" rel="self" type="application/rss+xml"/><item><title>数据一致性:云上的Debezium实践</title><link>https://facelezzzz.github.io/posts/debezium0/</link><pubDate>Sat, 18 Sep 2021 00:00:00 +0000</pubDate><guid>https://facelezzzz.github.io/posts/debezium0/</guid><description>最近在处理呼叫中心的控制组件时（该组件提供简单的API允许用户发起外部呼叫请求（指使用机器人对某人打电话））碰到一个问题，在过去，控制组件接收用户的提交的呼叫数据后写入mysql，然后控制组件从mysql扫描提交的数据并写入redis，在数据量很小的情况下，这种模式工作的很好，然而随着数据量快速上升，扫描变得越来越慢，开始影响到用户。
呼叫数据表一共有15列，其中有些关键的字段，例如:CREATE_TIME（创建时间）/STATE（状态，用来标记是否已经写入redis）/PHONE（用户的号码，可能是加密号）/ID（偏序自增的标识，作为主键，由发号器生成）/PAYLOAD（载体，必要的信息，可能会很长）。
在旧的模式下，定时任务从表中根据STATE扫描出未进入redis的数据，然后提交到redis队列中，当更改成功时修改每条数据的STATE字段，随着业务量上升，数据量开始快速膨胀（大约亿级每月），根据CREATE_TIME扫描的速度开始变慢，同时由于扫描耗时增长（数据库负载增加），也影响到插入，系统开始变得缓慢，需要优化。
有一些看上去不太可靠的方式：a.直接向redis写入呼叫数据，然后从redis同步数据到mysql（写入mysql是必要的，后续有其他组件依赖于此）；b.先向kafka写入呼叫数据，然后分别同步到redis和kafka; c.使用cdc工具 d.写入mysql时同时写入redis
a首先被否决，因为如果用户请求超时，则没有好的办法判断请求的状态（失败？成功写入redis？写入redis成功但是同步mysql异常？），此外从redis同步到mysql并没有合适的解决方案，此外在呼叫中心上，重复呼叫是需要避免的，系统需要提供幂性。
b其实看上去可以解决问题，但是还是缺失事务，因为提交呼叫数据时，有其他的同事务操作，当然可以通过一些手段避免事务，但是会增大复杂性。
d其实最简单，但是存在双写问题。
最后c方案被选择，CDC看上去完美符合需求，保持原来的写入逻辑，将扫描操作移除，改为由CDC捕获binlog同步变化到redis。
存在很多CDC工具，如canal，maxwell，debezium等，在一番测试后，最终确定了debezium。理由是debezium更符合需要，开源，由红帽支持，默认情况下使用kafka connect（解决了高可用的问题），此外写入到kafka能直接被下游的系统消费。
在云上部署 官网提供Demo在Docker上运行简单的示例，这里提供在k8s上部署的示例。
制作镜像: 在debezium官网下载debezium-connector-mysql-1.5.4.Final-plugin.tar
基于confluentinc公司的kafka connect构建需要的镜像： DOCKERFILE如下：
FROM confluentinc/cp-kafka-connect:6.2.0 ADD debezium-connector-mysql-1.5.4.Final-plugin.tar /plugins/ 构建完成后推送到必要的仓库。
制作Deployment 参照https://docs.confluent.io/platform/current/installation/docker/config-reference.html
apiVersion: apps/v1 kind: Deployment metadata: name: test-kafka-connector-debezium namespace: test labels: app: test-kafka-connector-debezium spec: replicas: 3 selector: matchLabels: app: test-kafka-connector-debezium template: metadata: labels: app: test-kafka-connector-debezium logging: 'true' spec: containers: - name: test-kafka-connector-debezium image: &amp;quot;&amp;lt;your_private_Harbor&amp;gt;/test/cp-kafka-connect-debezium:1.6.1&amp;quot; imagePullPolicy: Always ports: - containerPort: 8080 env: - name: CONNECT_BOOTSTRAP_SERVERS value: &amp;lt;kafka_cluter_addrs&amp;gt; - name: CONNECT_REST_PORT value: '&amp;lt;rest_port&amp;gt;' - name: CONNECT_GROUP_ID value: test-debezium-connect-group - name: CONNECT_CONFIG_STORAGE_TOPIC value: test-debezium-connect-config-storage - name: CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR value: '&amp;lt;factor_for_replacation&amp;gt;' - name: CONNECT_OFFSET_STORAGE_TOPIC value: test-debezium-connect-offset-storage - name: CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR value: 'factor_for_replacation' - name: CONNECT_STATUS_STORAGE_TOPIC value: test-debezium-connect-status-storage - name: CONNECT_STATUS_STORAGE_REPLICATION_FACTOR value: 'factor_for_replacation' - name: CONNECT_KEY_CONVERTER value: org.</description></item></channel></rss>